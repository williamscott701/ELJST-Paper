{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy import spatial\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import imp, multiprocessing\n",
    "import LDA_ETM as lda\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import utils as my_utils\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"dumps/mrf_lda/amazon_*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = glob.glob(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dumps/mrf_lda/amazon_movies_20000_glove_0.6_5topics',\n",
       " 'dumps/mrf_lda/amazon_movies_20000_glove_0.6_25topics',\n",
       " 'dumps/mrf_lda/amazon_kindle_20000_glove_0.6_5topics',\n",
       " 'dumps/mrf_lda/amazon_kindle_20000_glove_0.6_25topics',\n",
       " 'dumps/mrf_lda/amazon_home_20000_glove_0.6_5topics',\n",
       " 'dumps/mrf_lda/amazon_home_20000_glove_0.6_25topics']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(sampler):\n",
    "\n",
    "#     dt_distribution = sampler.theta()\n",
    "\n",
    "#     ss = silhouette_score(euclidean_distances(sampler.matrix),\n",
    "#                           dt_distribution.argmax(axis=1), metric='precomputed')\n",
    "\n",
    "#     dbs = davies_bouldin_score(sampler.matrix, dt_distribution.argmax(axis=1))\n",
    "\n",
    "    chs = my_utils.coherence_score(sampler.matrix, list(sampler.getTopKWords(10, sampler.words).values()), sampler.vocabulary)\n",
    "\n",
    "#     hsc = my_utils.get_hscore_multi(dt_distribution, sampler.matrix, sampler.n_topics, 2000)\n",
    "\n",
    "#     loli = sampler.loglikelihood()\n",
    "\n",
    "#     pxy = sampler.perplexity()\n",
    "    \n",
    "    chs2 = my_utils.coherence_score2(sampler.matrix, list(sampler.getTopKWords(10, sampler.words).values()), sampler.vocabulary)\n",
    "    \n",
    "    print(str(chs) + \",\" + str(chs2))\n",
    "\n",
    "#     print(str(hsc) + \",\" + str(ss) + \",\" + str(dbs) + \",\" + str(chs) + \",\" + str(loli) + \",\" + str(pxy), str(chs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumps/mrf_lda/amazon_movies_20000_glove_0.6_5topics\n",
      "-118.60515109761225,-3.9959295358488074\n",
      "dumps/mrf_lda/amazon_movies_20000_glove_0.6_25topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william18026/.conda/envs/python3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-112.88827880956568,-4.169000104763376\n",
      "dumps/mrf_lda/amazon_kindle_20000_glove_0.6_5topics\n",
      "-116.92236609329287,-3.657656996628018\n",
      "dumps/mrf_lda/amazon_kindle_20000_glove_0.6_25topics\n",
      "-110.85618885208243,-3.99348628125873\n",
      "dumps/mrf_lda/amazon_home_20000_glove_0.6_5topics\n",
      "-126.09473981299898,-5.047643063205587\n",
      "dumps/mrf_lda/amazon_home_20000_glove_0.6_25topics\n",
      "-125.56490511488602,-3.3029877330579804\n"
     ]
    }
   ],
   "source": [
    "for i in dumps:\n",
    "    print(i)\n",
    "    get_scores(sampler = joblib.load(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/william18026/Embedding-LJST-Paper/utils.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(my_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7073701412001971\n"
     ]
    }
   ],
   "source": [
    "get_scores(sampler = joblib.load(\"dumps/mrf_lda/amazon_movies_20000_glove_0.6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.763315597277788\n"
     ]
    }
   ],
   "source": [
    "get_scores(sampler = joblib.load(\"dumps/mrf_lda/amazon_kindle_20000_glove_0.6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.273371064348517\n"
     ]
    }
   ],
   "source": [
    "get_scores(sampler = joblib.load(\"dumps/mrf_lda/amazon_home_20000_glove_0.6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_dist = sampler.theta()\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_dist)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_dist.argmax(axis=1))\n",
    "# plt.legend(loc=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print \"\"\n",
    "#     print \"Topics:\", k\n",
    "#     print \"Coherance:\", my_utils.coherence_score(count_matrix, top_words, vocabulary)\n",
    "#     print \"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     print \"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_new",
   "language": "python",
   "name": "python3_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
